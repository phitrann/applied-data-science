{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -Uqqq pip --progress-bar off\n",
    "# !pip install -qqq torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116 --progress-bar off\n",
    "# !pip install -qqq transformers==4.35.2 --progress-bar off\n",
    "# !pip install -qqq langchain==0.0.266 --progress-bar off\n",
    "# !pip install -qqq openai==0.27.4 --progress-bar off\n",
    "# !pip install -Uqqq watermark==2.3.1 --progress-bar off\n",
    "# !pip install -Uqqq chromadb==0.4.5 --progress-bar off\n",
    "# !pip install -Uqqq tiktoken==0.3.3 --progress-bar off\n",
    "# !pip install -Uqqq youtube-transcript-api==0.5.0 --progress-bar off\n",
    "# !pip install -Uqqq pytube==12.1.3 --progress-bar off\n",
    "# !pip install -qqq sentence_transformers==2.2.2 --progress-bar off\n",
    "# !pip install -qqq InstructorEmbedding==1.0.1  --progress-bar off\n",
    "# !pip install -qqq xformers==0.0.20  --progress-bar off\n",
    "# !pip install -Uqqq unstructured[local-inference]==0.5.12 --progress-bar off\n",
    "# !pip install -Uqqq auto_gptq --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import textwrap\n",
    "import torch\n",
    "import chromadb\n",
    "import langchain\n",
    "import openai\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader, UnstructuredPDFLoader, YoutubeLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.llms import OpenAI, HuggingFacePipeline\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from auto_gptq import AutoGPTQForCausalLM\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer, pipeline, logging, TextStreamer\n",
    "from langchain.document_loaders.image import UnstructuredImageLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response(response: str):\n",
    "    print(\"\\n\".join(textwrap.wrap(response, width=100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = UnstructuredPDFLoader(\"../data/cv/CV _ Đinh Tuấn Nam_BE Developer(.NET)_HCM.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_pages = pdf_loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Dinh Tuan Nam B A C K E N D D E V E L O P E R\\n\\nPERSONAL DETAILS\\n\\n0799738634\\n\\nnamdinhtuan8@gmail.com\\n\\n26/09/2002\\n\\nHuynh Man Dat, District 5, TP Hồ Chí Minh\\n\\ngithub.com/dinhtuannam\\n\\nABOUT ME\\n\\nI am college student with a strong passion for technology and programming. My near goal is to become a junior backend developer. I have a good understanding of backend development using ASP.NET core , and I can also work effectively with the frontend development using React Framework with Typescript\\n\\nEDUCATION\\n\\nSaiGon University\\n\\nInformation Technology\\n\\n10/2020 - NOW\\n\\nSKILL\\n\\nIntermediate JWT .NET Core Database\\n\\nRedis RESTful\\n\\nSQL server\\n\\nPostgreSql\\n\\nC# ReactJS\\n\\nTypescript\\n\\nWORK EXPERIENCE\\n\\nBACK END DEVELOPER\\n\\n07/2023 - 02/2024\\n\\nSTVG Co.Ltd\\n\\nServerWater - Tech : ASP.NET Core , PostgreSQL , SSE - Role : Backend developer - Description: New installation, repair, replacement of water meters. Receive requests and assign tasks. Reports and statistics of jobs. - Responsibilities : This is a project built from scratch with a team size of 2 backend developers. My role involves collaborating with other team members to design the database and system. I am responsible for constructing functionalities based on client requirements and fixing bugs when system errors occur\\n\\nServerGIS - Tech : ASP.NET Core , PostgreSQL - Role : Backend developer - Description: The management and scheduling system for the maintenance of transportation equipment, roadways, water pillars, etc - Responsibilities : This is a previously built project where I am responsible for completing additional functionalities requested by the customer. My tasks include adding tables, creating entity relationships for those tables in the database, integrating new features into the system.\\n\\nPERSONAL PROJECT\\n\\nDevify - Online Learning Platform\\n\\n08/2023 - 12/2023\\n\\nASP.NET Core, PostgreSQL , React TS , Redis , JWT , CQRS, VNPay – An Online Learning Platform inspired by Udemy and F8, enabling users to purchase and access various online courses. This website is built with a backend using ASP.NET Core API and PostgreSQL, while the frontend utilizes React with TypeScript Additionally, the system is integrated with JWT for security purposes and Redis for caching - BE Github: https://github.com/dinhtuannam/devify-backend - FE Github: https://github.com/dinhtuannam/devify-frontend 03/2023 - 05/2023\\n\\nASP.NET Core MVC, SQL Server , Identity, Jquery, Ajax – This is an ecommerce web application for sneaker products, allowing users to quickly and conveniently view and purchase sneakers. The system is built with ASP.NET Core MVC, along with jQuery and Bootstrap for user interface handling - Github : https://github.com/dinhtuannam/MVC_Project\\n\\nPage 1 / 1 - © ITviec.com', metadata={'source': '../data/cv/CV _ Đinh Tuấn Nam_BE Developer(.NET)_HCM.pdf'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=512)\n",
    "texts = text_splitter.split_documents(pdf_pages)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "model_name = \"hkunlp/instructor-large\"\n",
    "\n",
    "hf_embeddings = HuggingFaceInstructEmbeddings(\n",
    "    model_name = model_name, cache_folder=\"../cache\") ## , model_kwargs = {'device': 'cuda'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(texts, hf_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
    "model_basename = \"gpt_model-4bit-128g\"\n",
    "\n",
    "use_triton = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True, cache_folder=\"../cache\")\n",
    "\n",
    "# model = AutoGPTQForCausalLM.from_quantized(model_name_or_path, cache_folder=\"../cache\",\n",
    "#         # model_basename=model_basename,\n",
    "#         use_safetensors=True,\n",
    "#         trust_remote_code=True,\n",
    "#         device='cuda:0',\n",
    "#         use_triton=use_triton,\n",
    "#         quantize_config=None)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             use_safetensors=True,\n",
    "                                             device_map = 'cuda',\n",
    "                                             trust_remote_code=True,\n",
    "                                             cache_dir=\"../cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(tokenizer, skip_prompt = True, skip_special_tokens = True)\n",
    "text_pipeline = pipeline(task = 'text-generation', model = model, tokenizer = tokenizer, streamer = streamer)\n",
    "llm = HuggingFacePipeline(pipeline = text_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(prompt, sys_prompt):\n",
    "    return f\"[INST] <<SYS>> {sys_prompt} <</SYS>> {prompt} [/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = \"Use following piece of context to answer the question in less than 20 words\"\n",
    "template = generate_prompt(\n",
    "    \"\"\"\n",
    "    {context}\n",
    "\n",
    "    Question : {question}\n",
    "    \"\"\"\n",
    "    , sys_prompt)\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(search_kwargs={\"k\": 2}),\n",
    "    return_source_documents = True,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/hotel/phit/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure! Here's the answer in less than 20 words:\n",
      "\n",
      "The candidate worked on the following projects:\n",
      "\n",
      "1. Devify - An online learning platform using ASP.NET Core, PostgreSQL, and React TS.\n",
      "2. MVC_Project - An e-commerce web application for sneaker products using ASP.NET Core MVC, SQL Server, and jQuery.\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain(\"what projects candidate worked on ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure! "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the answer in less than 20 words:\n",
      "\n",
      "Candidate studied at SaiGon University, majoring in Information Technology.\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain(\"where did candidate study?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the candidate has the following skillset:\n",
      "\n",
      "* Intermediate JWT .NET Core Database\n",
      "* Redis RESTful\n",
      "* SQL server\n",
      "* PostgreSql\n",
      "* C#\n",
      "* ReactJS\n",
      "* Typescript\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain(\"what skillset candidate has?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure! Here's the answer in less than 20 words:\n",
      "\n",
      "Contact details: 0799738634, namdinhtuan8@gmail.com.\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain(\"what's the contact detail of candidate?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's the answer in less than 20 words:\n",
      "\n",
      "The candidate has 2 years and 2 months of work experience, including internships.\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain(\"how many years of work experience candidate has? Include internships and the way you calculate that\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure! Here is the answer to your question in less than 20 words:\n",
      "\n",
      "Candidate worked at STVG Co. Ltd as a Backend Developer and at ITviec.com as a Developer.\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain(\"In which companies with what jobtitle did candidate work?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
